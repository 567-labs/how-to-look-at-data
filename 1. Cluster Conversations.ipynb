{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering Conversations: Discovering User Query Patterns\n\n> **Series Overview**: This is the first notebook in a three-part series on systematically analyzing and improving RAG systems. We'll move from raw user queries to production-ready classifiers that enable data-driven improvements.\n\n> **Prerequisites**: Install dependencies from `pyproject.toml` and set your `GOOGLE_API_KEY` for Gemini (required by Kura for summarization).\n\n## Why This Matters\n\nIn large-scale RAG applications, you'll encounter thousands of user queries. Manually reviewing each is impossible, and simple keyword counting misses deeper patterns. **Topic modeling helps you systematically identify patterns in user queries**, giving you insights into what users are asking and how well your system serves them.\n\nTopic modeling serves as the foundation for transforming raw user interactions into actionable insights by:\n\n1. **Revealing clusters** of similar queries that might need specialized handling\n2. **Providing evidence** for prioritizing improvements based on actual usage patterns\n3. **Highlighting gaps** where your retrieval might be underperforming\n4. **Creating a foundation** for building automated classification systems\n\nWhile topic modeling isn't objective ground truth, it's an invaluable discovery tool that helps you understand where to focus limited engineering resources based on real user behavior rather than intuition.\n\n## What You'll Learn\n\nIn this first notebook, you'll discover how to:\n\n1. **Prepare Query Data for Analysis**\n   - Format JSON data into Kura conversation objects\n   - Structure query-document pairs with proper metadata\n   - Set up data for effective clustering\n\n2. **Run Hierarchical Topic Clustering**\n   - Use Kura's LLM-enhanced clustering approach\n   - Generate meaningful summaries of conversation groups\n   - Visualize the topic hierarchies that emerge\n\n3. **Analyze and Interpret Results**\n   - Examine cluster themes and distribution patterns\n   - Identify high-impact areas for system improvements\n   - Recognize limitations in default summarization\n\n## What You'll Discover\n\n**By the end of this notebook, you'll uncover that just three major topics account for over two-thirds of all user queries**, with artifact management appearing as a dominant theme across 61% of conversations. However, you'll also discover that default summaries are too generic, missing crucial details about specific W&B features\u2014a limitation that motivates the custom summarization approach in the next notebook.\n\n## What Makes Kura Different\n\nTraditional topic modeling approaches like BERTopic or LDA rely purely on embeddings to group similar documents. **Kura enhances this process by leveraging LLMs to**:\n\n1. **Generate Meaningful Summaries** - Create human-readable descriptions rather than just numeric vectors\n2. **Extract Key Intents** - Identify specific user goals beyond surface-level keywords\n3. **Build Topic Hierarchies** - Create multi-level trees showing relationships between themes\n\nBy using LLMs for summarization before clustering, Kura produces more intuitive, actionable results than pure embedding-based approaches, setting the foundation for the systematic RAG improvement framework you'll build across this series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Understanding Our Dataset\n",
        "\n",
        "## Our Dataset\n",
        "\n",
        "We're working with 560 real user queries from the Weights & Biases documentation, each manually labelled with a retrieved relevant document. This dataset gives us direct insight into how users interact with ML experiment tracking documentation.\n",
        "\n",
        "By examining these query-document pairs, we gain valuable insights into:\n",
        "\n",
        "* What information users actively seek and how they phrase questions\n",
        "* Which documentation sections are most needed or confusing\n",
        "* How different query patterns cluster together, revealing common user challenges\n",
        "\n",
        "Topic modeling helps us identify semantically similar conversations, allowing us to group these queries into meaningful clusters that reveal broader patterns of user needs and pain points.\n",
        "\n",
        "For anyone building RAG systems, this kind of dataset is gold. It helps you understand user intent, find gaps in your documentation, and prioritize improvements based on actual usage patterns rather than guesswork.\n",
        "\n",
        "Without systematic analysis of such data, it's nearly impossible to identify patterns in how users interact with your system. Topic modeling gives us a data-driven way to improve retrieval strategies and function calling by understanding the most common user needs.\n",
        "\n",
        "## Preparing Our Data\n",
        "\n",
        "Before using Kura for topic modeling, we need to prepare our dataset. Each entry contains:\n",
        "- `query`: The user's original question\n",
        "- `matching_document`: The relevant document manually matched to this query\n",
        "- `query_id`: Unique identifier for the query\n",
        "- `matching_document_document_id`: ID of the matching document\n",
        "\n",
        "Let's examine what this data looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query_id': '5e878c76-25c1-4bad-8cae-6a40ca4c8138',\n",
              " 'query': 'experiment tracking',\n",
              " 'matching_document': '## Track Experiments\\n### How it works\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&B run.\\n2. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration (`wandb.config`).\\n3. Log metrics (`wandb.log()`) over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model weights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&B Experiment tracking workflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&B Run\\n\\nwandb.init(entity=\"\", project=\"my-project-name\")\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n# Import model and data\\n\\nmodel, dataloader = get\\\\_model(), get\\\\_data()\\n\\n# Model training code goes here\\n\\n# 3. Log metrics over time to visualize performance\\n\\nwandb.log({\"loss\": loss})\\n\\n# 4. Log an artifact to W&B\\n\\nwandb.log\\\\_artifact(model)\\n```',\n",
              " 'matching_document_document_id': '1c7f8798-7b2a-4baa-9829-14ada61db6bc',\n",
              " 'query_weight': 0.1}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"./data/conversations.json\") as f:\n",
        "    data = json.loads(f.read())\n",
        "\n",
        "data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This raw format isn't immediately useful for topic modeling. We need to transform it into something that Kura can process effectively. \n",
        "\n",
        "To do so, we'll convert it to a `Conversation` class which `Kura` exposes. This format allows Kura to:\n",
        "\n",
        "1. Process the conversation flow (even though we only have single queries in this example)\n",
        "2. Generate summaries of each conversation\n",
        "3. Embed and cluster conversations based on content and structure\n",
        "\n",
        "We'll create a function to convert each query-document pair into a Kura Conversation object with a single user Message that combines both the query and retrieved document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ivanleo/Documents/coding/chroma-workshop/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conversation</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">463244</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Message</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">463247</span><span style=\"font-weight: bold\">)</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\nUser Query: experiment tracking\\nRetrieved Information : ## Track Experiments\\n### How it </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">works\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&amp;B run.\\n2. Store a dictionary </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">of hyperparameters, such as learning rate or model type, into your configuration (`wandb.config`).\\n3. Log metrics </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">(`wandb.log()`) over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">weights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&amp;B Experiment tracking </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">workflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&amp;B Run\\n\\nwandb.init(entity=\"\", </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">project=\"my-project-name\")\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n#</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Import model and data\\n\\nmodel, dataloader = get\\\\_model(), get\\\\_data()\\n\\n# Model training code goes here\\n\\n# 3.</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Log metrics over time to visualize performance\\n\\nwandb.log({\"loss\": loss})\\n\\n# 4. Log an artifact to </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">W&amp;B\\n\\nwandb.log\\\\_artifact(model)\\n```\\n'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'query_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mConversation\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mchat_id\u001b[0m=\u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m,\n",
              "    \u001b[33mcreated_at\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m27\u001b[0m, \u001b[1;36m21\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m463244\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mcreated_at\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m27\u001b[0m, \u001b[1;36m21\u001b[0m, \u001b[1;36m3\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m463247\u001b[0m\u001b[1m)\u001b[0m,\n",
              "            \u001b[33mrole\u001b[0m=\u001b[32m'user'\u001b[0m,\n",
              "            \u001b[33mcontent\u001b[0m=\u001b[32m'\\nUser Query: experiment tracking\\nRetrieved Information : ## Track Experiments\\n### How it \u001b[0m\n",
              "\u001b[32mworks\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&B run.\\n2. Store a dictionary \u001b[0m\n",
              "\u001b[32mof hyperparameters, such as learning rate or model type, into your configuration \u001b[0m\u001b[32m(\u001b[0m\u001b[32m`wandb.config`\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n3. Log metrics \u001b[0m\n",
              "\u001b[32m(\u001b[0m\u001b[32m`wandb.log\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m`\u001b[0m\u001b[32m)\u001b[0m\u001b[32m over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model \u001b[0m\n",
              "\u001b[32mweights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&B Experiment tracking \u001b[0m\n",
              "\u001b[32mworkflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&B Run\\n\\nwandb.init\u001b[0m\u001b[32m(\u001b[0m\u001b[32mentity\u001b[0m\u001b[32m=\"\", \u001b[0m\n",
              "\u001b[32mproject\u001b[0m\u001b[32m=\u001b[0m\u001b[32m\"my\u001b[0m\u001b[32m-project-name\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n#\u001b[0m\n",
              "\u001b[32mImport model and data\\n\\nmodel, dataloader = get\\\\_model\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, get\\\\_data\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# Model training code goes here\\n\\n# 3.\u001b[0m\n",
              "\u001b[32mLog metrics over time to visualize performance\\n\\nwandb.log\u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"loss\": loss\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# 4. Log an artifact to \u001b[0m\n",
              "\u001b[32mW&B\\n\\nwandb.log\\\\_artifact\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmodel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\n'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'query_id'\u001b[0m: \u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from kura.types import Message, Conversation\n",
        "from datetime import datetime\n",
        "from rich import print\n",
        "\n",
        "def process_query_obj(obj:dict):\n",
        "    return Conversation(\n",
        "    chat_id=obj['query_id'],\n",
        "    created_at=datetime.now(),\n",
        "    messages=[\n",
        "        Message(\n",
        "            created_at=datetime.now(),\n",
        "            role=\"user\",\n",
        "            content=f\"\"\"\n",
        "User Query: {obj['query']}\n",
        "Retrieved Information : {obj['matching_document']}\n",
        "\"\"\"\n",
        "            )\n",
        "        ],\n",
        "        metadata={\n",
        "            'query_id': obj['query_id']\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "print(process_query_obj(data[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each individual `Conversation` object exposes a metadata field which allows us to provide additional context that can be valuable for analysis.\n",
        "\n",
        "In this case here, we add the Query ID to the metadata field so that we can preserve it for downstream processing. By properly structuring our data and enriching it with metadata, we're setting a strong foundation for the topic modeling work ahead. \n",
        "\n",
        "This careful preparation will pay off when we analyze the results and turn insights into actionable improvements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Clustering Process\n",
        "\n",
        "Now that we've converted our raw data into Kura's Conversation format, we're ready to run the clustering process. This is where we discover patterns across hundreds of conversations without needing to manually review each one.\n",
        "\n",
        "We'll use Kura's built-in clustering capabilities to group similar conversations together, identify common themes, and build a hierarchical organization of topics. The clustering algorithm combines embedding similarity with LLM-powered summarization to create meaningful, interpretable results.\n",
        "\n",
        "### The Clustering Pipeline\n",
        "\n",
        "The hierarchical clustering process follows a systematic approach:\n",
        "\n",
        "1. Summarization: First, each conversation is summarized by an LLM to capture its essence while removing sensitive details\n",
        "2. Embedding: These summaries are converted into vector embeddings that capture their semantic meaning\n",
        "3. Base Clustering: Similar conversations are grouped into small, initial clusters\n",
        "4. Hierarchical Merging: Similar clusters are progressively combined into broader categories\n",
        "5. Naming and Description: Each cluster receives a descriptive name and explanation generated by an LLM\n",
        "\n",
        "By starting with many detailed clusters before gradually reducing them to more general topics, we can preserve these meaningful patterns while making it easy for humans to review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Summarising 560 conversations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 560/560 [00:15<00:00, 36.78it/s]\n",
            "Embedding Summaries: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 560/560 [00:06<00:00, 90.22it/s] \n",
            "Generating Base Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 56/56 [00:02<00:00, 21.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting with 56 clusters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 56/56 [00:01<00:00, 35.68it/s]\n",
            "Generating Meta Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [00:06<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reduced to 45 clusters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 45/45 [00:01<00:00, 36.75it/s]\n",
            "Generating Meta Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:05<00:00,  1.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reduced to 36 clusters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 36/36 [00:01<00:00, 33.56it/s]\n",
            "Generating Meta Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:04<00:00,  1.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reduced to 19 clusters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 19/19 [00:01<00:00, 17.48it/s]\n",
            "Generating Meta Clusters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:03<00:00,  1.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reduced to 9 clusters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ivanleo/Documents/coding/chroma-workshop/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from kura import Kura\n",
        "\n",
        "kura = Kura()\n",
        "conversations = [process_query_obj(obj) for obj in data]\n",
        "clusters = await kura.cluster_conversations(conversations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the output, we can see the consolidation process happening in real-time. Kura starts with 56 base clusters, then gradually merges them through multiple rounds until we reach 9 final top-level clusters. Each merge combines similar topics while preserving the essential distinctions between different conversation types.\n",
        "\n",
        "Now, let's examine these top-level clusters to understand the main themes in our data. \n",
        "\n",
        "By looking at the cluster names, descriptions, and sizes, we can quickly identify what users are discussing most frequently and how these topics relate to each other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Use Weights &amp; Biases to track, manage, and log your machine learning models</span> : The clusters involve using Weights &amp; \n",
              "Biases for experiment tracking, data handling, model training, evaluation, and prompt management. It includes \n",
              "integrating LangChain, transforming dataframes, managing training runs, detaching hooks from models, and linking \n",
              "runs to a model registry, primarily within Python environments using the wandb library.  : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">93</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Guide data exporting to CSV, PDF, and LaTeX</span> : The cluster provides assistance and instructions for effectively \n",
              "exporting data in the desired format : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Integrate and explain experiment tracking tools</span> : The clusters involve requests for explaining experiment tracking \n",
              "tool parameters, summarizing documentation, best practices, features, data logging, functionalities, and management\n",
              "of experiment tracking tool runs, including accessing artifacts, managing projects, filtering, sorting, searching \n",
              "runs, and integrating with other software, integrating LLMs, generating code to log molecular data, and \n",
              "troubleshooting experiment tracking tools, focusing on setup, integration with frameworks, logging metrics, \n",
              "troubleshooting errors, and secure usage : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Automate and parallelize hyperparameter optimization sweeps.</span> : The clusters involve automating, parallelizing, and \n",
              "optimizing hyperparameter sweeps, including best practices for hyperparameter tuning, metric logging, sweep \n",
              "configuration in YAML and Python, troubleshooting sweeps, parallelization on multi-GPU machines, and accessing \n",
              "sweep results, often referencing the API and configuration examples.  : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Manage and version artifacts and data in tools</span> : The clusters involve managing, versioning, and summarizing \n",
              "artifacts and data within specific tool ecosystems, including metadata management, storage configuration, and \n",
              "access control best practices : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">59</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Customize Charts and UI Elements with Vega Specifications</span> : The clusters involve users customizing charts and UI \n",
              "elements using Vega specifications, focusing on appearance modifications, conditional styling, and data \n",
              "visualization with tools like the <span style=\"color: #008000; text-decoration-color: #008000\">'datum'</span> function within a specific platform : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Explain team collaboration, job security, and model logging</span> : These clusters cover team collaboration, secure \n",
              "training jobs, and model logging, including team roles, report sharing, IAM roles, and API usage.  : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Explain Python library usage with code snippets</span> : The requests centered around providing guidance on integrating \n",
              "specific libraries into Python code. The guidance included installation instructions, authentication, best \n",
              "practices, code snippets, and error handling specific to the library's usage : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Teach experiment tracking and artifact management with W&amp;B</span> : The requests involve teaching users how to use the \n",
              "wandb library, including experiment tracking, data and artifact management, and troubleshooting sweeps and \n",
              "configurations using the W&amp;B API and Python SDK : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">143</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mUse Weights & Biases to track, manage, and log your machine learning models\u001b[0m : The clusters involve using Weights & \n",
              "Biases for experiment tracking, data handling, model training, evaluation, and prompt management. It includes \n",
              "integrating LangChain, transforming dataframes, managing training runs, detaching hooks from models, and linking \n",
              "runs to a model registry, primarily within Python environments using the wandb library.  : \u001b[1;36m93\u001b[0m\n",
              "\n",
              "\u001b[1mGuide data exporting to CSV, PDF, and LaTeX\u001b[0m : The cluster provides assistance and instructions for effectively \n",
              "exporting data in the desired format : \u001b[1;36m5\u001b[0m\n",
              "\n",
              "\u001b[1mIntegrate and explain experiment tracking tools\u001b[0m : The clusters involve requests for explaining experiment tracking \n",
              "tool parameters, summarizing documentation, best practices, features, data logging, functionalities, and management\n",
              "of experiment tracking tool runs, including accessing artifacts, managing projects, filtering, sorting, searching \n",
              "runs, and integrating with other software, integrating LLMs, generating code to log molecular data, and \n",
              "troubleshooting experiment tracking tools, focusing on setup, integration with frameworks, logging metrics, \n",
              "troubleshooting errors, and secure usage : \u001b[1;36m140\u001b[0m\n",
              "\n",
              "\u001b[1mAutomate and parallelize hyperparameter optimization sweeps.\u001b[0m : The clusters involve automating, parallelizing, and \n",
              "optimizing hyperparameter sweeps, including best practices for hyperparameter tuning, metric logging, sweep \n",
              "configuration in YAML and Python, troubleshooting sweeps, parallelization on multi-GPU machines, and accessing \n",
              "sweep results, often referencing the API and configuration examples.  : \u001b[1;36m60\u001b[0m\n",
              "\n",
              "\u001b[1mManage and version artifacts and data in tools\u001b[0m : The clusters involve managing, versioning, and summarizing \n",
              "artifacts and data within specific tool ecosystems, including metadata management, storage configuration, and \n",
              "access control best practices : \u001b[1;36m59\u001b[0m\n",
              "\n",
              "\u001b[1mCustomize Charts and UI Elements with Vega Specifications\u001b[0m : The clusters involve users customizing charts and UI \n",
              "elements using Vega specifications, focusing on appearance modifications, conditional styling, and data \n",
              "visualization with tools like the \u001b[32m'datum'\u001b[0m function within a specific platform : \u001b[1;36m13\u001b[0m\n",
              "\n",
              "\u001b[1mExplain team collaboration, job security, and model logging\u001b[0m : These clusters cover team collaboration, secure \n",
              "training jobs, and model logging, including team roles, report sharing, IAM roles, and API usage.  : \u001b[1;36m41\u001b[0m\n",
              "\n",
              "\u001b[1mExplain Python library usage with code snippets\u001b[0m : The requests centered around providing guidance on integrating \n",
              "specific libraries into Python code. The guidance included installation instructions, authentication, best \n",
              "practices, code snippets, and error handling specific to the library's usage : \u001b[1;36m6\u001b[0m\n",
              "\n",
              "\u001b[1mTeach experiment tracking and artifact management with W&B\u001b[0m : The requests involve teaching users how to use the \n",
              "wandb library, including experiment tracking, data and artifact management, and troubleshooting sweeps and \n",
              "configurations using the W&B API and Python SDK : \u001b[1;36m143\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get top-level clusters (those without parents)\n",
        "parent_clusters = [cluster for cluster in clusters if cluster.parent_id is None]\n",
        "\n",
        "# Format each cluster's info with name, description and number of chats\n",
        "formatted_clusters = []\n",
        "for cluster in parent_clusters:\n",
        "    cluster_info = (\n",
        "        f\"[bold]{cluster.name}[/bold] : {cluster.description} : {len(cluster.chat_ids)}\"\n",
        "    )\n",
        "    formatted_clusters.append(cluster_info)\n",
        "\n",
        "# Join with newlines and print\n",
        "print(\"\\n\\n\".join(formatted_clusters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysing Our Results\n",
        "\n",
        "### Understanding Our Top-Level Clusters\n",
        "\n",
        "Looking at the nine top-level clusters generated by Kura, we can identify clear patterns in how users are interacting with the documentation.\n",
        "\n",
        "Three major clusters account for 67% of all queries:\n",
        "1. Experiment Tracking and Artifact Management (143 conversations)\n",
        "2. Tool Integration and Documentation (140 conversations)\n",
        "3. Core Functionality Usage (93 conversations)\n",
        "\n",
        "What's particularly notable is that artifact management appears as a significant theme across multiple clusters. Three clusters specifically focus on managing, creating, and versioning artifacts, totaling 342 conversations (61% of all queries). \n",
        "\n",
        "This suggests that users are consistently trying to figure out how to properly track and organize the results of their experiments.\n",
        "\n",
        "This clustering suggests that improving documentation and features around artifact management would address the majority of user needs. By focusing on how users track experiment results and manage artifacts across their workflow, we could significantly improve the user experience while addressing the most common pain points revealed in these clusters.RetryClaude can make mistakes. Please double-check responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysing Our Summaries\n",
        "\n",
        "Let's now examine what are some of the summaries that were generated by Kura for our individual query document pairs. \n",
        "\n",
        "To do so, we'll read in the list of conversations that we started with and then find their corresponding summary. This will allows us to then evaluate how representative the conversation summary is of the individual conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The user's overall request for the assistant is to provide information about experiment tracking using a specific \n",
              "tool, including how it works and pseudocode examples for implementation.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "The user's overall request for the assistant is to provide information about experiment tracking using a specific \n",
              "tool, including how it works and pseudocode examples for implementation.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: experiment tracking\n",
              "Retrieved Information : ## Track Experiments\n",
              "### How it works\n",
              "Track a machine learning experiment with a few lines of code:\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Create a W&amp;B run.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration \n",
              "<span style=\"font-weight: bold\">(</span>`wandb.config`<span style=\"font-weight: bold\">)</span>.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Log metrics <span style=\"font-weight: bold\">(</span>`<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">()</span>`<span style=\"font-weight: bold\">)</span> over time in a training loop, such as accuracy and loss.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Save outputs of a run, like the model weights or a table of predictions.  \n",
              "\n",
              "The proceeding pseudocode demonstrates a common W&amp;B Experiment tracking workflow:  \n",
              "\n",
              "```python showLineNumbers\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Start a W&amp;B Run\n",
              "\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.init</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">entity</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"my-project-name\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Save mode inputs and hyperparameters\n",
              "\n",
              "wandb.config.learning\\_rate = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>\n",
              "\n",
              "# Import model and data\n",
              "\n",
              "model, dataloader = get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_model</span><span style=\"font-weight: bold\">()</span>, get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_data</span><span style=\"font-weight: bold\">()</span>\n",
              "\n",
              "# Model training code goes here\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Log metrics over time to visualize performance\n",
              "\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">({</span><span style=\"color: #008000; text-decoration-color: #008000\">\"loss\"</span>: loss<span style=\"font-weight: bold\">})</span>\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Log an artifact to W&amp;B\n",
              "\n",
              "wandb.log\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_artifact</span><span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>\n",
              "```\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: experiment tracking\n",
              "Retrieved Information : ## Track Experiments\n",
              "### How it works\n",
              "Track a machine learning experiment with a few lines of code:\n",
              "\u001b[1;36m1\u001b[0m. Create a W&B run.\n",
              "\u001b[1;36m2\u001b[0m. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration \n",
              "\u001b[1m(\u001b[0m`wandb.config`\u001b[1m)\u001b[0m.\n",
              "\u001b[1;36m3\u001b[0m. Log metrics \u001b[1m(\u001b[0m`\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m`\u001b[1m)\u001b[0m over time in a training loop, such as accuracy and loss.\n",
              "\u001b[1;36m4\u001b[0m. Save outputs of a run, like the model weights or a table of predictions.  \n",
              "\n",
              "The proceeding pseudocode demonstrates a common W&B Experiment tracking workflow:  \n",
              "\n",
              "```python showLineNumbers\n",
              "\n",
              "# \u001b[1;36m1\u001b[0m. Start a W&B Run\n",
              "\n",
              "\u001b[1;35mwandb.init\u001b[0m\u001b[1m(\u001b[0m\u001b[33mentity\u001b[0m=\u001b[32m\"\"\u001b[0m, \u001b[33mproject\u001b[0m=\u001b[32m\"my\u001b[0m\u001b[32m-project-name\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# \u001b[1;36m2\u001b[0m. Save mode inputs and hyperparameters\n",
              "\n",
              "wandb.config.learning\\_rate = \u001b[1;36m0.01\u001b[0m\n",
              "\n",
              "# Import model and data\n",
              "\n",
              "model, dataloader = get\\\u001b[1;35m_model\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, get\\\u001b[1;35m_data\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# Model training code goes here\n",
              "\n",
              "# \u001b[1;36m3\u001b[0m. Log metrics over time to visualize performance\n",
              "\n",
              "\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\u001b[32m\"loss\"\u001b[0m: loss\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# \u001b[1;36m4\u001b[0m. Log an artifact to W&B\n",
              "\n",
              "wandb.log\\\u001b[1;35m_artifact\u001b[0m\u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m\n",
              "```\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The user's overall request for the assistant is to summarize the information about Bayesian optimization for \n",
              "hyperparameter tuning, including inputs, outputs, advantages, and disadvantages using Python libraries such as \n",
              "bayes_opt and W&amp;B\n",
              "</pre>\n"
            ],
            "text/plain": [
              "The user's overall request for the assistant is to summarize the information about Bayesian optimization for \n",
              "hyperparameter tuning, including inputs, outputs, advantages, and disadvantages using Python libraries such as \n",
              "bayes_opt and W&B\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: Bayesian optimization\n",
              "Retrieved Information : ## Methods for Automated Hyperparameter Optimization\n",
              "### Bayesian Optimization\n",
              "Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function to determine the next set\n",
              "of hyperparameters to evaluate. In contrast to grid search and random search, Bayesian optimization is an informed \n",
              "search method.  \n",
              "\n",
              "### Inputs  \n",
              "\n",
              "* A set of hyperparameters you want to optimize\n",
              "* A continuous search space for each hyperparameter as a value range\n",
              "* A performance metric to optimize\n",
              "* Explicit number of runs: Because the search space is continuous, you must manually stop the search or define a \n",
              "maximum number of runs.  \n",
              "\n",
              "The differences in grid search are highlighted in bold above.  \n",
              "\n",
              "A popular way to implement Bayesian optimization in Python is to use BayesianOptimization from the \n",
              "<span style=\"font-weight: bold\">(</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/fmfn/BayesianOptimization)</span> library. Alternatively, as shown below, you can set up Bayesian \n",
              "optimization for hyperparameter tuning with W&amp;B.  \n",
              "\n",
              "### Steps  \n",
              "\n",
              "### Output  \n",
              "\n",
              "### Advantages  \n",
              "\n",
              "### Disadvantages\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: Bayesian optimization\n",
              "Retrieved Information : ## Methods for Automated Hyperparameter Optimization\n",
              "### Bayesian Optimization\n",
              "Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function to determine the next set\n",
              "of hyperparameters to evaluate. In contrast to grid search and random search, Bayesian optimization is an informed \n",
              "search method.  \n",
              "\n",
              "### Inputs  \n",
              "\n",
              "* A set of hyperparameters you want to optimize\n",
              "* A continuous search space for each hyperparameter as a value range\n",
              "* A performance metric to optimize\n",
              "* Explicit number of runs: Because the search space is continuous, you must manually stop the search or define a \n",
              "maximum number of runs.  \n",
              "\n",
              "The differences in grid search are highlighted in bold above.  \n",
              "\n",
              "A popular way to implement Bayesian optimization in Python is to use BayesianOptimization from the \n",
              "\u001b[1m(\u001b[0m\u001b[4;94mhttps://github.com/fmfn/BayesianOptimization\u001b[0m\u001b[4;94m)\u001b[0m library. Alternatively, as shown below, you can set up Bayesian \n",
              "optimization for hyperparameter tuning with W&B.  \n",
              "\n",
              "### Steps  \n",
              "\n",
              "### Output  \n",
              "\n",
              "### Advantages  \n",
              "\n",
              "### Disadvantages\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The user's overall request for the assistant is to provide instructions on how to integrate the Weights &amp; Biases \n",
              "library with PyTorch for experiment tracking. The instructions include code snippets for logging metrics, tracking \n",
              "gradients, and saving models..\n",
              "</pre>\n"
            ],
            "text/plain": [
              "The user's overall request for the assistant is to provide instructions on how to integrate the Weights & Biases \n",
              "library with PyTorch for experiment tracking. The instructions include code snippets for logging metrics, tracking \n",
              "gradients, and saving models..\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: How to integrate Weights &amp; Biases with PyTorch?\n",
              "Retrieved Information : ## \ud83d\udd25 = W&amp;B \u2795 PyTorch\n",
              "\n",
              "Use Weights &amp; Biases for machine learning experiment tracking, dataset versioning, and project collaboration.  \n",
              "\n",
              "## What this notebook covers:  \n",
              "\n",
              "We show you how to integrate Weights &amp; Biases with your PyTorch code to add experiment tracking to your pipeline.  \n",
              "\n",
              "## The resulting interactive W&amp;B dashboard will look like:  \n",
              "\n",
              "## In pseudocode, what we'll do is:  \n",
              "\n",
              "```\n",
              "# import the library\n",
              "import wandb\n",
              "\n",
              "# start a new experiment\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.init</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"new-sota-model\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "#\u2003capture a dictionary of hyperparameters with config\n",
              "wandb.config = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"learning\\_rate\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.001</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"epochs\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"batch\\_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">}</span>\n",
              "\n",
              "# set up model and data\n",
              "model, dataloader = get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_model</span><span style=\"font-weight: bold\">()</span>, get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_data</span><span style=\"font-weight: bold\">()</span>\n",
              "\n",
              "# optional: track gradients\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.watch</span><span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "for batch in dataloader:\n",
              "metrics = model.training\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_step</span><span style=\"font-weight: bold\">()</span>\n",
              "#\u2003log metrics inside your training loop to visualize model performance\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">(</span>metrics<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "# optional: save model at the end\n",
              "model.to\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_onnx</span><span style=\"font-weight: bold\">()</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.save</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"model.onnx\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "```  \n",
              "\n",
              "## Follow along with a video tutorial!\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: How to integrate Weights & Biases with PyTorch?\n",
              "Retrieved Information : ## \ud83d\udd25 = W&B \u2795 PyTorch\n",
              "\n",
              "Use Weights & Biases for machine learning experiment tracking, dataset versioning, and project collaboration.  \n",
              "\n",
              "## What this notebook covers:  \n",
              "\n",
              "We show you how to integrate Weights & Biases with your PyTorch code to add experiment tracking to your pipeline.  \n",
              "\n",
              "## The resulting interactive W&B dashboard will look like:  \n",
              "\n",
              "## In pseudocode, what we'll do is:  \n",
              "\n",
              "```\n",
              "# import the library\n",
              "import wandb\n",
              "\n",
              "# start a new experiment\n",
              "\u001b[1;35mwandb.init\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject\u001b[0m=\u001b[32m\"new\u001b[0m\u001b[32m-sota-model\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "#\u2003capture a dictionary of hyperparameters with config\n",
              "wandb.config = \u001b[1m{\u001b[0m\u001b[32m\"learning\\_rate\"\u001b[0m: \u001b[1;36m0.001\u001b[0m, \u001b[32m\"epochs\"\u001b[0m: \u001b[1;36m100\u001b[0m, \u001b[32m\"batch\\_size\"\u001b[0m: \u001b[1;36m128\u001b[0m\u001b[1m}\u001b[0m\n",
              "\n",
              "# set up model and data\n",
              "model, dataloader = get\\\u001b[1;35m_model\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, get\\\u001b[1;35m_data\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# optional: track gradients\n",
              "\u001b[1;35mwandb.watch\u001b[0m\u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m\n",
              "\n",
              "for batch in dataloader:\n",
              "metrics = model.training\\\u001b[1;35m_step\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "#\u2003log metrics inside your training loop to visualize model performance\n",
              "\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0mmetrics\u001b[1m)\u001b[0m\n",
              "\n",
              "# optional: save model at the end\n",
              "model.to\\\u001b[1;35m_onnx\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1;35mwandb.save\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"model.onnx\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "```  \n",
              "\n",
              "## Follow along with a video tutorial!\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from kura.types import ConversationSummary\n",
        "\n",
        "with open(kura.summary_checkpoint_name) as f:\n",
        "    summaries = [ConversationSummary(**json.loads(item)) for item in f.readlines()]\n",
        "\n",
        "with open(kura.conversation_checkpoint_name) as f:\n",
        "    conversations = [Conversation(**item) for item in json.loads(f.read())]\n",
        "\n",
        "id_to_conversation = {\n",
        "    conversation.chat_id: conversation\n",
        "    for conversation in conversations\n",
        "}\n",
        "\n",
        "for i in range(3):\n",
        "    print(summaries[i].summary)\n",
        "    print(id_to_conversation[summaries[i].chat_id].messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\n### What You Learned\n\nIn this notebook, you discovered how to transform raw user queries into actionable insights for RAG system improvements. You learned to:\n\n- **Prepare query data for Kura** by formatting JSON data into Conversation objects with proper metadata\n- **Run hierarchical clustering** using Kura's built-in capabilities to group similar conversations\n- **Analyze clustering results** to identify the most common user query patterns and pain points\n\n### What We Accomplished\n\nBy leveraging Kura's clustering capabilities, we organized 560 user queries into nine meaningful clusters that revealed clear patterns in how users interact with Weights & Biases documentation. The analysis showed that three major topics\u2014experiment tracking, tool integration, and artifact management\u2014account for over two-thirds of all queries, with artifact management appearing as a significant theme across multiple clusters (61% of conversations).\n\nHowever, we also identified critical limitations in the default summarization approach. Our generated summaries lacked specificity about the tools users wanted to use and sometimes included irrelevant context from retrieved documents. For example, summaries described queries as \"user seeks information about tracking\" rather than capturing the specific W&B features involved.\n\n### Next: Better Summaries\n\nWhile our clustering revealed valuable high-level patterns, the generic summaries limit our ability to understand specific user needs. In the next notebook, \"Better Summaries\", we'll address this limitation by building a custom summarization model that:\n\n- **Identifies specific W&B features** (Artifacts, Configs, Reports) mentioned in each query\n- **Captures precise user intent** rather than generic descriptions  \n- **Creates domain-specific summaries** tailored to W&B terminology and workflows\n\nBy replacing vague summaries like \"user seeks information about tracking\" with precise descriptions like \"user is managing W&B Artifacts for model versioning\", we'll create clusters that better reflect real user needs and provide more targeted, actionable insights for system improvements."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}