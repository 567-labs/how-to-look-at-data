{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Summaries: Customizing for Domain-Specific Clustering\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "The default summarization approach we used in our initial clustering produced overly generic summaries that failed to capture the essence of Weights & Biases-specific queries. When working with specialized domains like machine learning experiment tracking, these generic summaries miss critical details that would enable more effective query segmentation.\n",
    "\n",
    "Custom summarization allows us to transform vague descriptions like \"The user's overall request for the assistant is to provide information about experiment tracking using a specific tool\" into precise, actionable insights like \"The user is using Weights and Biases's experiment tracking features to monitor model training (metrics, configs, artifacts).\" This precision is critical for building representative clusters that truly reflect how users interact with the platform.\n",
    "\n",
    "Domain-specific summaries help us by:\n",
    "1. Capturing the exact W&B features users are working with\n",
    "2. Identifying specific user goals and pain points\n",
    "3. Revealing underlying patterns in how users approach documentation\n",
    "4. Creating a foundation for more targeted system improvements\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this section, you'll discover how to:\n",
    "\n",
    "1. **Create a Custom Summary Model**\n",
    "   - Define a specialized summarization approach for W&B queries\n",
    "   - Structure prompts that extract domain-specific information\n",
    "   - Implement length constraints for concise, focused summaries\n",
    "\n",
    "2. **Generate Better Summaries**\n",
    "   - Compare default vs. custom summarization approaches\n",
    "   - See how domain knowledge improves summary quality\n",
    "   - Create summaries that highlight specific W&B features\n",
    "\n",
    "3. **Build More Representative Clusters**\n",
    "   - Use improved summaries as the foundation for clustering\n",
    "   - Configure clustering parameters for optimal results\n",
    "   - Visualize how better summaries lead to more cohesive clusters\n",
    "\n",
    "By customizing our summarization approach to our specific domain, we'll create clusters that better reflect real user needs and provide actionable insights for improving our RAG system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Summary Model\n",
    "\n",
    "To address the limitations we identified in our default summaries, we'll now implement our own custom summary model specific to Weights & Biases queries. By replacing the generic summarization approach with a domain-tailored solution, we can generate summaries that precisely capture the tools, features, and goals relevant to W&B users.\n",
    "\n",
    "The `WnBSummaryModel` class we'll create extends Kura's base `SummaryModel` with a specialized prompt that instructs the model to:\n",
    "\n",
    "1. Identify specific W&B features mentioned in the query (e.g., Artifacts, Configs, Reports)\n",
    "2. Clearly state the problem the user is trying to solve\n",
    "3. Format responses concisely (25 words or less) to ensure summaries remain focused\n",
    "\n",
    "This approach generates summaries that are not only more informative but also more consistent, making them ideal building blocks for meaningful clustering. Let's implement our custom model and see how it transforms our understanding of user query patterns.\n",
    "\n",
    "### Loading in Conversation\n",
    "\n",
    "Let's first start by loading in our conversations and parsing it into a list of `Conversation` objects that `Kura` can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanleo/Documents/coding/chroma-workshop/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lib.conversation import process_query_obj\n",
    "import json\n",
    "\n",
    "with open(\"./data/conversations.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "conversations = [process_query_obj(obj) for obj in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to see how our default summaries look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarising 2 conversations: 100%|██████████| 2/2 [00:01<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_id='5e878c76-25c1-4bad-8cae-6a40ca4c8138' summary=\"The user's overall request for the assistant is to explain how to track machine learning experiments using a specific library by creating a run, storing hyperparameters, logging metrics, and saving outputs of the run as demonstrated in the pseudocode provided .\" metadata={'conversation_turns': 1, 'query_id': '5e878c76-25c1-4bad-8cae-6a40ca4c8138'}\n",
      "chat_id='d7b77e8a-e86c-4953-bc9f-672618cdb751' summary=\"The user's overall request for the assistant is to summarize information about Bayesian optimization, a hyperparameter tuning technique, and its implementation in Python using libraries like bayes_opt.\" metadata={'conversation_turns': 1, 'query_id': 'd7b77e8a-e86c-4953-bc9f-672618cdb751'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from kura.summarisation import SummaryModel\n",
    "\n",
    "summaries = await SummaryModel().summarise(conversations[:2])\n",
    "for summary in summaries:\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these default summaries, we can identify several key limitations that prevent them from being truly useful for clustering W&B-specific queries:\n",
    "\n",
    "**Problems with Default Summaries**\n",
    "\n",
    "1. Lack of Specificity: The first summary refers to \"a specific tool\" rather than explicitly naming Weights & Biases, missing the opportunity to highlight the domain context.\n",
    "\n",
    "2. Missing Feature Details: Neither summary identifies which specific W&B features the users are interested in (experiment tracking, Bayesian optimization for hyperparameter tuning), which would be crucial for meaningful clustering.\n",
    "\n",
    "These generic summaries would lead to clusters based primarily on query structure (\"users asking for information\") rather than meaningful W&B feature categories or user goals. \n",
    "\n",
    "By defining our own summarisation model, we can address these limitations and cluster our user queries based off the specific problems and features they are trying to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Our New Summary Model\n",
    "\n",
    "Let's now define a new `WnBSummaryModel` which will help address the shortcomings of the default summarisation model.\n",
    "\n",
    "We'll do so by modifying the `summarise_conversation` method so that our summaries can become more precise and feature-focused. This allows us to better reflect how users interact with Weights and Biases and in turn translate to more representative clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kura.types import Conversation, ConversationSummary\n",
    "from kura.summarisation import SummaryModel, GeneratedSummary\n",
    "\n",
    "\n",
    "class WnBSummaryModel(SummaryModel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    async def summarise_conversation(\n",
    "        self, conversation: Conversation\n",
    "    ) -> ConversationSummary:\n",
    "        # Get the default client and semaphore - This is going to be the Gemini GenAI client and a semaphore limit of around 50 concurrent requests \n",
    "        client = self.clients.get(\"default\")  # type: ignore\n",
    "        sem = self.sems.get(\"default\")  # type: ignore\n",
    "\n",
    "        async with sem:\n",
    "            resp = await client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": \"\"\"\n",
    "Summarize the user's issue based on their query and the retrieved information from the Weights and Biases FAQ section.\n",
    "\n",
    "In your response:\n",
    "\n",
    "1. Identify the specific Weights and Biases feature(s) the user is working with (e.g., Artifacts, Configs, Reports), including any features implied but not directly named.\n",
    "\n",
    "2. Clearly state the problem they're trying to solve.\n",
    "\n",
    "Format your response in 25 words or less following these patterns:\n",
    "\n",
    "If the query has a clear feature and problem:\n",
    "\"The user is using Weights and Biases's [feature(s)] to [problem] and needs help with [specific issue].\"\n",
    "\n",
    "If the query is ambiguous (e.g., \"Bayesian optimization\" without context):\n",
    "\"The user made a query about [topic].\"\n",
    "\n",
    "Analyze both the query and retrieved documents carefully to identify the user's actual goal rather than just repeating their keywords. Here is the message context that you should refer to:\n",
    "<context>\n",
    "{{ context }}\n",
    "</context>\n",
    "\n",
    "Be as specific as possible in your response.\n",
    "\"\"\",\n",
    "                    },\n",
    "                ],\n",
    "                response_model=GeneratedSummary,\n",
    "                context={\"context\": conversation.messages[0].content},\n",
    "            )\n",
    "\n",
    "            return ConversationSummary(\n",
    "                chat_id=conversation.chat_id,\n",
    "                summary=resp.summary,\n",
    "                metadata={\n",
    "                    \"conversation_turns\": len(conversation.messages),\n",
    "                },\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the generated summaries by calling the `summarise` method below. We'll be using the same conversations above which we generated summaries for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarising 2 conversations: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConversationSummary</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The user is using Weights and Biases' experiment tracking features to track machine learning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiments, including logging metrics, saving hyperparameters, and saving model artifacts, and needs help </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">understanding the overall workflow.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'conversation_turns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mConversationSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mchat_id\u001b[0m=\u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m,\n",
       "    \u001b[33msummary\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m user is using Weights and Biases' experiment tracking features to track machine learning \u001b[0m\n",
       "\u001b[32mexperiments, including logging metrics, saving hyperparameters, and saving model artifacts, and needs help \u001b[0m\n",
       "\u001b[32munderstanding the overall workflow.\"\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'conversation_turns'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConversationSummary</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d7b77e8a-e86c-4953-bc9f-672618cdb751'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The user is exploring Bayesian optimization for hyperparameter tuning within Weights &amp; Biases and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">needs guidance on its implementation and usage.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'conversation_turns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mConversationSummary\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mchat_id\u001b[0m=\u001b[32m'd7b77e8a-e86c-4953-bc9f-672618cdb751'\u001b[0m,\n",
       "    \u001b[33msummary\u001b[0m=\u001b[32m'The user is exploring Bayesian optimization for hyperparameter tuning within Weights & Biases and \u001b[0m\n",
       "\u001b[32mneeds guidance on its implementation and usage.'\u001b[0m,\n",
       "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'conversation_turns'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summaries = await WnBSummaryModel().summarise(conversations[:2])\n",
    "for summary in summaries:\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with Enhanced Summaries\n",
    "\n",
    "Now that we've developed a more domain-specific summarization approach tailored to the Weights & Biases ecosystem, we can apply these improved summaries to our clustering process. \n",
    "\n",
    "Our custom `WnBSummaryModel` captures the specific features, workflows, and user intentions that were missing in the default summaries, providing a stronger foundation for meaningful topic discovery.\n",
    "\n",
    "This will help us to reveal patterns in feature usage, common pain points and documentation gaps that might have been obscured in our analysis in our previous notebook. Let's see this in action below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarising 560 conversations: 100%|██████████| 560/560 [00:15<00:00, 35.40it/s]\n",
      "Embedding Summaries: 100%|██████████| 560/560 [00:05<00:00, 100.27it/s]\n",
      "Generating Base Clusters: 100%|██████████| 56/56 [00:03<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 56 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Clusters: 100%|██████████| 56/56 [00:01<00:00, 45.32it/s]\n",
      "Generating Meta Clusters: 100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 27 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Clusters: 100%|██████████| 27/27 [00:00<00:00, 27.52it/s]\n",
      "Generating Meta Clusters: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 22 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Clusters: 100%|██████████| 22/22 [00:01<00:00, 20.16it/s]\n",
      "Generating Meta Clusters: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 11 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Clusters: 100%|██████████| 11/11 [00:00<00:00, 23.41it/s]\n",
      "Generating Meta Clusters: 100%|██████████| 1/1 [00:03<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 6 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Clusters: 100%|██████████| 6/6 [00:01<00:00,  4.37it/s]\n",
      "Generating Meta Clusters: 100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 6 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Clusters: 100%|██████████| 6/6 [00:00<00:00, 13.74it/s]\n",
      "Generating Meta Clusters: 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced to 3 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanleo/Documents/coding/chroma-workshop/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from kura import Kura\n",
    "\n",
    "kura = Kura(\n",
    "    summarisation_model=WnBSummaryModel(),\n",
    "    max_clusters=5,\n",
    "    checkpoint_dir=\"./checkpoints_2\"\n",
    ")\n",
    "\n",
    "clusters = await kura.cluster_conversations(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(d3629de048f44355abd533566718fbca) Manage and Debug Machine Learning Experiments with Weights &amp; Biases</span> : The \n",
       "clusters involve using Weights &amp; Biases <span style=\"font-weight: bold\">(</span>wandb<span style=\"font-weight: bold\">)</span> for experiment tracking, metric logging, model versioning, \n",
       "hyperparameter optimization, and integration with various machine learning models and frameworks, debugging, \n",
       "resolving errors, and customizing charts, plots, and reports, to gain insights into model training process, \n",
       "performance and optimize experiment runs.. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">497</span>\n",
       "\n",
       "  • <span style=\"font-weight: bold\">Manage machine learning experiments with Weights &amp; Biases</span> : The clusters involve using Weights &amp; Biases <span style=\"font-weight: bold\">(</span>wandb<span style=\"font-weight: bold\">)</span>\n",
       "for experiment tracking, metric logging, model versioning, hyperparameter optimization, and integration with \n",
       "various machine learning models and frameworks, including best practices for naming, grouping, and logging data, \n",
       "and troubleshooting integration issues, to gain insights into model training process and performance and optimize \n",
       "experiment runs.. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">264</span>\n",
       "    + <span style=\"font-weight: bold\">Use Weights &amp; Biases for machine learning experiment management</span> : The clusters involve using Weights &amp; Biases\n",
       "<span style=\"font-weight: bold\">(</span>wandb<span style=\"font-weight: bold\">)</span> for experiment tracking, metric logging, model versioning, hyperparameter optimization, and integration \n",
       "with various machine learning models and frameworks, including best practices for naming, grouping, and logging \n",
       "data, and troubleshooting integration issues, to gain insights into model training process and performance and \n",
       "optimize experiment runs.. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">264</span>\n",
       "\n",
       "\n",
       "  • <span style=\"font-weight: bold\">Manage and analyze machine learning models with Weights &amp; Biases</span> : The clusters involve using Weights &amp; Biases \n",
       "<span style=\"font-weight: bold\">(</span>W&amp;B<span style=\"font-weight: bold\">)</span> for machine learning model management, experiment tracking, versioning, and artifact analysis, including \n",
       "storing, logging, querying, and integrating them into workflows, along with manipulating and analyzing Weights &amp; B \n",
       "tables using Pandas : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">136</span>\n",
       "    + <span style=\"font-weight: bold\">Manage and analyze machine learning models using Weights &amp; Biases</span> : The clusters involve using Weights &amp; \n",
       "Biases <span style=\"font-weight: bold\">(</span>W&amp;B<span style=\"font-weight: bold\">)</span> for machine learning model management, experiment tracking, versioning, and artifact analysis, \n",
       "including storing, logging, querying, and integrating them into workflows, along with manipulating and analyzing \n",
       "Weights &amp; B tables using Pandas : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">136</span>\n",
       "\n",
       "\n",
       "  • <span style=\"font-weight: bold\">Debug and Customize Weights &amp; Biases Experiments</span> : The clusters involve users seeking assistance with \n",
       "debugging, resolving errors, and customizing charts, plots, and reports in Weights &amp; Biases, including logging \n",
       "metrics, tracking data, managing GPU usage, and resolving errors during machine learning experiments and \n",
       "hyperparameter optimization, and programmatically accessing runs and their attributes : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span>\n",
       "    + <span style=\"font-weight: bold\">Debug and Customize Weights &amp; Biases Experiments and Visualizations</span> : The clusters involve users seeking \n",
       "assistance with debugging, resolving errors, and customizing charts, plots, and reports in Weights &amp; Biases, \n",
       "including logging metrics, tracking data, managing GPU usage, and resolving errors during machine learning \n",
       "experiments and hyperparameter optimization, and programmatically accessing runs and their attributes : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">97</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "====\n",
       "\n",
       "\n",
       "<span style=\"font-weight: bold\">(461d0109b1134f8cadf7fb3a4d5818df) Integrate Weights &amp; Biases with cloud services and Docker images</span> : Integrate \n",
       "Weights &amp; Biases with cloud services and Docker images: Users needed assistance with Weights &amp; Biases \n",
       "authentication, particularly in cloud environments like AWS SageMaker, and with integrations involving custom \n",
       "Docker images. They sought guidance on secure key management, service accounts, and configuring SSO on the \n",
       "server-side W&amp;B app, as well as examples for setting up W&amp;B Launch with SageMaker and custom images <span style=\"font-weight: bold\">(</span>BYOI<span style=\"font-weight: bold\">)</span>. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "\n",
       "  • <span style=\"font-weight: bold\">Integrate Weights &amp; Biases with cloud services and Docker images</span> : Users needed assistance with Weights &amp; \n",
       "Biases authentication, particularly in cloud environments like AWS SageMaker, and with integrations involving \n",
       "custom Docker images. They sought guidance on secure key management, service accounts, and configuring SSO on the \n",
       "server-side W&amp;B app, as well as examples for setting up W&amp;B Launch with SageMaker and custom images <span style=\"font-weight: bold\">(</span>BYOI<span style=\"font-weight: bold\">)</span>. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "    + <span style=\"font-weight: bold\">Configure and Integrate W&amp;B with Cloud Services</span> : Users needed assistance with Weights &amp; Biases \n",
       "authentication, particularly in cloud environments like AWS SageMaker, and with integrations involving custom \n",
       "Docker images. They sought guidance on secure key management, service accounts, and configuring SSO on the \n",
       "server-side W&amp;B app, as well as examples for setting up W&amp;B Launch with SageMaker and custom images <span style=\"font-weight: bold\">(</span>BYOI<span style=\"font-weight: bold\">)</span>. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "====\n",
       "\n",
       "\n",
       "<span style=\"font-weight: bold\">(93cbee975f974856ba0e707921dcc2d0) Manage and export data from Weights &amp; Biases</span> : The clusters describe managing \n",
       "and exporting data, artifacts, access control, and permissions from the Weights &amp; Biases platform, including team \n",
       "roles, collaboration features, and data formats, using the web panel or API, sometimes without an API key. It also \n",
       "includes understanding team roles, collaboration features, setting permissions, controlling access, and enabling \n",
       "collaboration with both W&amp;B users and non-users, including handling sensitive data and resolving edit conflicts for\n",
       "multi-user access, admin roles, and SSO configurations : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span>\n",
       "\n",
       "  • <span style=\"font-weight: bold\">Manage access control and permissions for Weights &amp; Biases.</span> : The clusters describe managing and understanding \n",
       "weights and biases teams, projects, platform features, access control, permissions, and sharing capabilities within\n",
       "the Weights &amp; Biases platform. It also includes understanding team roles, collaboration features, setting \n",
       "permissions, controlling access, and enabling collaboration with both W&amp;B users and non-users, including handling \n",
       "sensitive data and resolving edit conflicts for multi-user access, admin roles, and SSO configurations.  : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>\n",
       "    + <span style=\"font-weight: bold\">Control access and permissions in Weights &amp; Biases</span> : The clusters describe managing and understanding weights\n",
       "and biases teams, projects, platform features, access control, permissions, and sharing capabilities within the \n",
       "Weights &amp; Biases platform. It also includes understanding team roles, collaboration features, setting permissions, \n",
       "controlling access, and enabling collaboration with both W&amp;B users and non-users, including handling sensitive data\n",
       "and resolving edit conflicts for multi-user access, admin roles, and SSO configurations.  : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>\n",
       "\n",
       "\n",
       "  • <span style=\"font-weight: bold\">Export data and artifacts from Weights &amp; Biases</span> : The clusters involve users seeking assistance with exporting \n",
       "various data formats and downloading artifacts from the Weights &amp; Biases platform, often through the web panel or \n",
       "API, sometimes without an API key : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>\n",
       "    + <span style=\"font-weight: bold\">Export data and artifacts from Weights &amp; Biases</span> : The clusters involve users seeking assistance with \n",
       "exporting various data formats and downloading artifacts from the Weights &amp; Biases platform, often through the web \n",
       "panel or API, sometimes without an API key : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "====\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1md3629de048f44355abd533566718fbca\u001b[0m\u001b[1m)\u001b[0m\u001b[1m Manage and Debug Machine Learning Experiments with Weights & Biases\u001b[0m : The \n",
       "clusters involve using Weights & Biases \u001b[1m(\u001b[0mwandb\u001b[1m)\u001b[0m for experiment tracking, metric logging, model versioning, \n",
       "hyperparameter optimization, and integration with various machine learning models and frameworks, debugging, \n",
       "resolving errors, and customizing charts, plots, and reports, to gain insights into model training process, \n",
       "performance and optimize experiment runs.. : \u001b[1;36m497\u001b[0m\n",
       "\n",
       "  • \u001b[1mManage machine learning experiments with Weights & Biases\u001b[0m : The clusters involve using Weights & Biases \u001b[1m(\u001b[0mwandb\u001b[1m)\u001b[0m\n",
       "for experiment tracking, metric logging, model versioning, hyperparameter optimization, and integration with \n",
       "various machine learning models and frameworks, including best practices for naming, grouping, and logging data, \n",
       "and troubleshooting integration issues, to gain insights into model training process and performance and optimize \n",
       "experiment runs.. : \u001b[1;36m264\u001b[0m\n",
       "    + \u001b[1mUse Weights & Biases for machine learning experiment management\u001b[0m : The clusters involve using Weights & Biases\n",
       "\u001b[1m(\u001b[0mwandb\u001b[1m)\u001b[0m for experiment tracking, metric logging, model versioning, hyperparameter optimization, and integration \n",
       "with various machine learning models and frameworks, including best practices for naming, grouping, and logging \n",
       "data, and troubleshooting integration issues, to gain insights into model training process and performance and \n",
       "optimize experiment runs.. : \u001b[1;36m264\u001b[0m\n",
       "\n",
       "\n",
       "  • \u001b[1mManage and analyze machine learning models with Weights & Biases\u001b[0m : The clusters involve using Weights & Biases \n",
       "\u001b[1m(\u001b[0mW&B\u001b[1m)\u001b[0m for machine learning model management, experiment tracking, versioning, and artifact analysis, including \n",
       "storing, logging, querying, and integrating them into workflows, along with manipulating and analyzing Weights & B \n",
       "tables using Pandas : \u001b[1;36m136\u001b[0m\n",
       "    + \u001b[1mManage and analyze machine learning models using Weights & Biases\u001b[0m : The clusters involve using Weights & \n",
       "Biases \u001b[1m(\u001b[0mW&B\u001b[1m)\u001b[0m for machine learning model management, experiment tracking, versioning, and artifact analysis, \n",
       "including storing, logging, querying, and integrating them into workflows, along with manipulating and analyzing \n",
       "Weights & B tables using Pandas : \u001b[1;36m136\u001b[0m\n",
       "\n",
       "\n",
       "  • \u001b[1mDebug and Customize Weights & Biases Experiments\u001b[0m : The clusters involve users seeking assistance with \n",
       "debugging, resolving errors, and customizing charts, plots, and reports in Weights & Biases, including logging \n",
       "metrics, tracking data, managing GPU usage, and resolving errors during machine learning experiments and \n",
       "hyperparameter optimization, and programmatically accessing runs and their attributes : \u001b[1;36m97\u001b[0m\n",
       "    + \u001b[1mDebug and Customize Weights & Biases Experiments and Visualizations\u001b[0m : The clusters involve users seeking \n",
       "assistance with debugging, resolving errors, and customizing charts, plots, and reports in Weights & Biases, \n",
       "including logging metrics, tracking data, managing GPU usage, and resolving errors during machine learning \n",
       "experiments and hyperparameter optimization, and programmatically accessing runs and their attributes : \u001b[1;36m97\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "====\n",
       "\n",
       "\n",
       "\u001b[1m(\u001b[0m\u001b[1m461d0109b1134f8cadf7fb3a4d5818df\u001b[0m\u001b[1m)\u001b[0m\u001b[1m Integrate Weights & Biases with cloud services and Docker images\u001b[0m : Integrate \n",
       "Weights & Biases with cloud services and Docker images: Users needed assistance with Weights & Biases \n",
       "authentication, particularly in cloud environments like AWS SageMaker, and with integrations involving custom \n",
       "Docker images. They sought guidance on secure key management, service accounts, and configuring SSO on the \n",
       "server-side W&B app, as well as examples for setting up W&B Launch with SageMaker and custom images \u001b[1m(\u001b[0mBYOI\u001b[1m)\u001b[0m. : \u001b[1;36m10\u001b[0m\n",
       "\n",
       "  • \u001b[1mIntegrate Weights & Biases with cloud services and Docker images\u001b[0m : Users needed assistance with Weights & \n",
       "Biases authentication, particularly in cloud environments like AWS SageMaker, and with integrations involving \n",
       "custom Docker images. They sought guidance on secure key management, service accounts, and configuring SSO on the \n",
       "server-side W&B app, as well as examples for setting up W&B Launch with SageMaker and custom images \u001b[1m(\u001b[0mBYOI\u001b[1m)\u001b[0m. : \u001b[1;36m10\u001b[0m\n",
       "    + \u001b[1mConfigure and Integrate W&B with Cloud Services\u001b[0m : Users needed assistance with Weights & Biases \n",
       "authentication, particularly in cloud environments like AWS SageMaker, and with integrations involving custom \n",
       "Docker images. They sought guidance on secure key management, service accounts, and configuring SSO on the \n",
       "server-side W&B app, as well as examples for setting up W&B Launch with SageMaker and custom images \u001b[1m(\u001b[0mBYOI\u001b[1m)\u001b[0m. : \u001b[1;36m10\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "====\n",
       "\n",
       "\n",
       "\u001b[1m(\u001b[0m\u001b[1m93cbee975f974856ba0e707921dcc2d0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m Manage and export data from Weights & Biases\u001b[0m : The clusters describe managing \n",
       "and exporting data, artifacts, access control, and permissions from the Weights & Biases platform, including team \n",
       "roles, collaboration features, and data formats, using the web panel or API, sometimes without an API key. It also \n",
       "includes understanding team roles, collaboration features, setting permissions, controlling access, and enabling \n",
       "collaboration with both W&B users and non-users, including handling sensitive data and resolving edit conflicts for\n",
       "multi-user access, admin roles, and SSO configurations : \u001b[1;36m53\u001b[0m\n",
       "\n",
       "  • \u001b[1mManage access control and permissions for Weights & Biases.\u001b[0m : The clusters describe managing and understanding \n",
       "weights and biases teams, projects, platform features, access control, permissions, and sharing capabilities within\n",
       "the Weights & Biases platform. It also includes understanding team roles, collaboration features, setting \n",
       "permissions, controlling access, and enabling collaboration with both W&B users and non-users, including handling \n",
       "sensitive data and resolving edit conflicts for multi-user access, admin roles, and SSO configurations.  : \u001b[1;36m40\u001b[0m\n",
       "    + \u001b[1mControl access and permissions in Weights & Biases\u001b[0m : The clusters describe managing and understanding weights\n",
       "and biases teams, projects, platform features, access control, permissions, and sharing capabilities within the \n",
       "Weights & Biases platform. It also includes understanding team roles, collaboration features, setting permissions, \n",
       "controlling access, and enabling collaboration with both W&B users and non-users, including handling sensitive data\n",
       "and resolving edit conflicts for multi-user access, admin roles, and SSO configurations.  : \u001b[1;36m40\u001b[0m\n",
       "\n",
       "\n",
       "  • \u001b[1mExport data and artifacts from Weights & Biases\u001b[0m : The clusters involve users seeking assistance with exporting \n",
       "various data formats and downloading artifacts from the Weights & Biases platform, often through the web panel or \n",
       "API, sometimes without an API key : \u001b[1;36m13\u001b[0m\n",
       "    + \u001b[1mExport data and artifacts from Weights & Biases\u001b[0m : The clusters involve users seeking assistance with \n",
       "exporting various data formats and downloading artifacts from the Weights & Biases platform, often through the web \n",
       "panel or API, sometimes without an API key : \u001b[1;36m13\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "====\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get top-level clusters (those without parents)\n",
    "parent_clusters = [cluster for cluster in clusters if cluster.parent_id is None]\n",
    "\n",
    "# Format each cluster's info with name, description and number of chats\n",
    "formatted_clusters = []\n",
    "for parent in parent_clusters:\n",
    "    \n",
    "    # Add parent cluster info\n",
    "    cluster_info = (\n",
    "        f\"[bold]({parent.id}) {parent.name}[/bold] : {parent.description} : {len(parent.chat_ids)}\\n\"\n",
    "    )\n",
    "    \n",
    "    # Get and format child clusters\n",
    "    child_clusters = [c for c in clusters if c.parent_id == parent.id]\n",
    "    for child in child_clusters:\n",
    "        cluster_info += f\"\\n  • [bold]{child.name}[/bold] : {child.description} : {len(child.chat_ids)}\"\n",
    "        child_child_clusters = [c for c in clusters if c.parent_id == child.id]\n",
    "        for child_child in child_child_clusters:\n",
    "            if child_child.parent_id == child.id:\n",
    "                cluster_info += f\"\\n    + [bold]{child_child.name}[/bold] : {child_child.description} : {len(child_child.chat_ids)}\"\n",
    "        \n",
    "        cluster_info += \"\\n\\n\"\n",
    "    \n",
    "    formatted_clusters.append(cluster_info)\n",
    "    formatted_clusters.append(\"\\n====\\n\")\n",
    "\n",
    "# Join with newlines and print\n",
    "print(\"\\n\\n\".join(formatted_clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these new clusters, we've identified three main types of clusters \n",
    "\n",
    "1. **Access Controls** People are asking for how to handle and export data in Weights and Biases\n",
    "2. **Deployment** : People are asking for how to manage keys, service accounts and also integrate the data with Sagemaker and other custom images.\n",
    "3. **Managing and Tracking Experiment Data** : People are looking for help on how to specifically manage Artifacts, Generate Visualisation, Integrate W&B with their pytorch and multi-gpu runs etc.\n",
    "\n",
    "This is a huge upgrade from the previous clusters that we obtained and gives us much more information that we can work with. Exploring these clusters in more depth would probably yield us a lot more information which we can use to train classifiers down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've significantly enhanced our final clusters by implementing domain-specific clustering for user queries. By using a specific summary prompt that is tailored to Weights and Biases termininology and features, we transformed vague descriptions into precise, actionable insights that the issues that users faced when interacting with the platform.\n",
    "\n",
    "Our custom WnBSummaryModel helped us identify three distinct user query patterns:\n",
    "\n",
    "1. Users seeking help with access controls and data export\n",
    "2. Users trying to integrate W&B with cloud services and Docker images\n",
    "3. Users managing and tracking experiment data through artifacts, visualizations, and multi-GPU runs\n",
    "\n",
    "If we had user satisfaction data, we could identify which cluster types have the lowest satisfaction scores and prioritize those areas first. For example, if users asking about artifacts management consistently report poor experiences, we could build specialized retrieval pipelines with fine-tuned embeddings just for those queries.\n",
    "\n",
    "In the next notebook, we'll take this a step further by using the `instructor` library to build a classifier that can automatically identify queries related to managing, creating, and versioning artifacts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
